{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 貸出・返却台数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールのインポート  \n",
    "\n",
    "table.ipynbをモジュールとして読み込み, CSVファイルの内容ごとに結合・前処理したDataFrameにアクセスする．\n",
    "\n",
    "主なDataFrameは以下の5種類．  \n",
    "\n",
    "- table.station：station_data  \n",
    "- table.status：status_data  \n",
    "- table.trip：trip_data\n",
    "- table.weather：weather_data\n",
    "- table.feature：table.tripにtable.stationとtable.weatherの必要な情報を結合したDataFrame  \n",
    "\n",
    "＊結合前の各CSVファイルにもアクセスできる(例：table.station_201608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table.ipynb\n",
    "import sys\n",
    "import notebookutil as nbu\n",
    "sys.meta_path.append(nbu.NotebookFinder())\n",
    "import table\n",
    "\n",
    "# その他に必要なモジュール(機械学習用のモジュールは使用時に読み込む)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 現状の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### landmarkごとのtripの利用時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = table.station.landmark.unique()\n",
    "duration = table.features[[\"Start Landmark\", \"End Landmark\", \"Duration\"]]\n",
    "landmark_duration = []\n",
    "for landmark in landmarks:\n",
    "    duration_sub = duration.loc[(duration[\"Start Landmark\"] == landmark) | (duration[\"End Landmark\"] == landmark), \"Duration\"]\n",
    "    landmark_duration.append([landmark, duration_sub.mean(), len(duration_sub)])\n",
    "duration = pd.DataFrame(landmark_duration).set_index(0)\n",
    "duration = duration.rename(columns = {1:\"Mean duration(min)\", 2:\"Trip count\"})\n",
    "duration.index.names = ['Landmark']\n",
    "\n",
    "duration = duration.sort_values(\"Trip count\", ascending=False)\n",
    "duration.append(pd.DataFrame({\"Mean duration(min)\": table.features.Duration.mean(), \"Trip count\":duration[\"Trip count\"].sum()}, index = [\"Total\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trip count ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trip = table.features[[\"Start Landmark\", \"End Landmark\" ]]\n",
    "trip = (trip.groupby([\"Start Landmark\", \"End Landmark\" ]).size().to_frame(\"Count\")).sort_values(by=\"Count\", ascending=False)\n",
    "trip[\"Ratio\"] = trip[\"Count\"] / len(table.features)\n",
    "trip.drop(\"Count\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各ステーションの1日あたりの貸出台数と返却台数の分布\n",
    "\n",
    "目的：各stationの貸出台数と返却台数の相関や利用状況の確認, \n",
    "\n",
    "貸出台数と返却台数には強い正の相関があることがわかる  \n",
    "＊相関係数0.98, p値 5.9e-49, 仮説「貸出台数と返却台数は無相関」は有意水準1%で棄却される\n",
    "\n",
    "→以降は貸出台数と返却台数の和(=利用回数)を見ていく　　\n",
    "  \n",
    "また，1日あたりの利用回数は平均27, 分散29, 最小値0.5, 最大値150と振れ幅が大きい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 各stationの1日あたりの貸出台数, 返却台数を格納したDataFrameの作成\n",
    "trip_count = table.station[[\"station_id\",\"landmark\", \"installation\"]].copy()\n",
    "trip_count[\"Days\"] = (pd.Timestamp(\"2016-08-31\") - trip_count[\"installation\"]).dt.days\n",
    "trip_count = trip_count.drop(\"installation\", axis=1)\n",
    "trip_count = trip_count.set_index(\"station_id\")\n",
    "trip_count[\"Rental Count\"] = table.trip.groupby(\"Start Terminal\").size()\n",
    "trip_count[\"Rental per Day\"] = trip_count[\"Rental Count\"] / trip_count[\"Days\"]\n",
    "trip_count[\"Return Count\"] = table.trip.groupby(\"End Terminal\").size()\n",
    "trip_count[\"Return per Day\"] = trip_count[\"Return Count\"] / trip_count[\"Days\"]\n",
    "trip_count[\"Total Count\"] =trip_count[\"Rental Count\"] + trip_count[\"Return Count\"]\n",
    "trip_count[\"Total per Day\"] = trip_count[\"Total Count\"] / trip_count[\"Days\"]\n",
    "trip_count = trip_count.sort_values(\"Total per Day\", ascending=False)\n",
    "trip_count.reset_index(level=0, inplace=True)\n",
    "\n",
    "# # 可視化\n",
    "a = trip_count.plot.scatter(\n",
    "    x='Rental per Day',y='Return per Day', figsize=(5, 5), color=\"dodgerblue\", title=\"Distribution of rental count and return count\"\n",
    ")\n",
    "plt.xlabel(\"Rental count per day\")\n",
    "plt.ylabel(\"Return count per day\")\n",
    "\n",
    "# # 各要素にラベルを表示\n",
    "for k, v in trip_count.iterrows():\n",
    "    a.annotate(v[0], xy=(v[4],v[6]))\n",
    "    \n",
    "# 1日あたりの利用回数(貸出台数と返却台数の和)上位5件と下位5件を表示\n",
    "trip_count = trip_count.set_index(\"station_id\")\n",
    "trip_count.head(5).append(trip_count.tail(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1日あたりの貸出台数と返却台数の相関係数\n",
    "r, p = stats.pearsonr(trip_count[\"Rental per Day\"], trip_count[\"Return per Day\"])\n",
    "print(\"相関係数\", r)\n",
    "print(\"p値\", p)\n",
    "print(\"p < 0.01:\", p < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1日あたりの利用回数の基本統計量の確認\n",
    "trip_count[\"Total per Day\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各stationの利用回数と占有率の時間推移を見る．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = table.trip[[\"Start Terminal\", \"End Terminal\"]].groupby([\"Start Terminal\",\"End Terminal\"]).size().to_frame(\"Count\")\n",
    "M= M.reset_index(level=[0, 1])\n",
    "M= M.pivot(index =\"Start Terminal\", columns=\"End Terminal\", values=\"Count\").fillna(0).apply(lambda x: x/x.sum(), axis=1)\n",
    "M.loc[64, :].sort_values(ascending=False).head()\n",
    "# M.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for station_id in available_ratio.columns:\n",
    "station_id = 70\n",
    "available_ratio_sub =  pd.DataFrame(available_ratio.loc[:, station_id]).copy()\n",
    "available_ratio_sub[\"Time\"] = list(map(lambda x:pd.to_datetime(x).hour, available_ratio.index))[:len(available_ratio_sub)]\n",
    "available_ratio_sub.groupby(\"Time\").mean().plot(color=\"dodgerblue\",ylim =(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1月あたりの利用回数と天候の特徴量との関係をしらべて，大まかな相関を見る\n",
    "→ 風の影響が意外と強い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 分析対象の指定\n",
    "station_id = 0 # station_idの指定．id=0のとき， 全てのデータ\n",
    "landmark = ['', 'San Jose', 'San Francisco', 'Palo Alto', 'Mountain View', 'Redwood City'][2] # lanrmarkの指定． lanrmark = \"\"のとき，全てのデータ．\n",
    "sub_title = \"\" #グラフのtitleに使用\n",
    "\n",
    "# landmarkの取得\n",
    "if station_id != 0:\n",
    "    landmark = table.station.landmark[table.station.station_id == station_id].values[0]\n",
    "    sub_title = f\"station:{station_id}\" \n",
    "\n",
    "\n",
    "# weatherから必要な情報を抽出し， monthly_weatherデータフレームを作る \n",
    "\n",
    "# weatherテーブルから， stationとlandmarkが一致する行を抽出し， Dateをインデックスとして指定する．\n",
    "monthly_weather = table.weather[[\n",
    "    \"PDT\", \n",
    "    \"Mean TemperatureC\",\n",
    "    'Mean Dew PointC',\n",
    "    'Mean Humidity',\n",
    "    'Mean Sea Level PressureIn',\n",
    "    'Mean VisibilityMiles',\n",
    "    'Mean Wind SpeedMPH',\n",
    "    'Max Gust SpeedMPH',\n",
    "    'CloudCover',\n",
    "    'Events',\n",
    "    'WindDirDegrees',\n",
    "    \"PrecipitationMM\"\n",
    "]][table.weather.landmark == landmark].copy()\n",
    "monthly_weather[\"PDT\"] = list(map(lambda x:x.strftime('%Y-%m'), monthly_weather.PDT))\n",
    "monthly_weather = monthly_weather.set_index(\"PDT\") \n",
    "monthly_weather.index.names = [\"Year Month\"]  \n",
    "monthly_weather = monthly_weather.groupby(\"Year Month\").mean()\n",
    "\n",
    "\n",
    "# 月別の利用回数を格納したDataFrame(monthly_trip)の作成\n",
    "\n",
    "if station_id != 0: # station_idの指定がある場合\n",
    "    monthly_trip = table.features[(table.features[\"Start ID\"] == station_id)\n",
    "                                  | (table.features[\"End ID\"] == station_id)].groupby(\"Year Month\").size().to_frame(\"Count\")\n",
    "    \n",
    "elif  landmark != '' and station_id == 0: # landmarkの指定がある場合(station_idの指定がある場合は無効)\n",
    "    monthly_trip = table.features[(table.features[\"Start Landmark\"] == landmark)\n",
    "                                  | (table.features[\"End Landmark\"] == landmark)].groupby(\"Year Month\").size().to_frame(\"Count\")\n",
    "    sub_title = f\"landmark:{landmark}\" \n",
    "else: # station_id, landmarkの指定がない場合は全てのデータを分析対象とする．\n",
    "    monthly_trip = table.features.groupby(\"Year Month\").size().to_frame(\"Count\")\n",
    "    sub_title = \"All data\" \n",
    "\n",
    "# 30で割り，1日あたりの利用回数を求める\n",
    "monthly_trip[\"Count\"] = monthly_trip[\"Count\"] / 30\n",
    "\n",
    "    \n",
    "# 結合\n",
    "monthly = monthly_weather.join(monthly_trip)\n",
    "\n",
    "# 相関係数の絶対値が降順になるように表示\n",
    "monthly_corr = monthly.corr()\n",
    "monthly_corr[\"abs\"] = monthly_corr.Count.abs()\n",
    "monthly_corr = monthly_corr.sort_values(\"abs\", ascending=False) #.drop(\"abs\", axis=1)\n",
    "monthly_corr.Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(monthly_corr.Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 気温と利用回数の関係\n",
    "ax = monthly[\"Count\"].plot(kind=\"bar\", figsize=(15, 5), color='orange', width=0.3,  legend=True, title=f\"Count and Temperature ({sub_title}) \")  \n",
    "monthly[\"Max Gust SpeedMPH\"].plot(figsize=(15, 5), ax=ax, secondary_y=True, color=\"orangered\", linewidth=4, legend=True, rot=90) # rot:軸のメモリを回転\n",
    "ax.set_ylabel('Count')\n",
    "plt.ylabel('Mean Temperature (C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 気温と利用回数の関係\n",
    "ax = monthly[\"Count\"].plot(kind=\"bar\", figsize=(15, 5), color='orange', width=0.3,  legend=True, title=f\"Count and Temperature ({sub_title}) \")  \n",
    "monthly[\"Mean TemperatureC\"].plot(figsize=(15, 5), ax=ax, secondary_y=True, color=\"orangered\", linewidth=4, legend=True, rot=90) # rot:軸のメモリを回転\n",
    "ax.set_ylabel('Count')\n",
    "plt.ylabel('Mean Temperature (C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降水量と利用回数の関係\n",
    "fig = plt.figure() \n",
    "ax = fig.add_subplot(111)\n",
    "ax2 = ax.twinx() \n",
    "monthly[\"Count\"].plot(kind=\"bar\", figsize=(15, 5), color='orange',  width=0.3,  position=1, ax=ax, legend=True,  title=f\"Count and Precipitation ({sub_title})\")\n",
    "monthly[\"PrecipitationMM\"].plot(kind = \"bar\", figsize=(15, 5), color=\"dodgerblue\",width=0.3, position=0) \n",
    "monthly[\"PrecipitationMM\"].plot(kind = \"bar\", figsize=(15, 5), color=\"dodgerblue\",width=0.3, position=0, ax=ax, legend=True)\n",
    "ax.set_ylabel('Count')\n",
    "ax2.set_ylabel('Precipitation (mm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  曜日と1日あたりの利用回数の平均値の関係\n",
    "landmark問わず休日に少ない傾向あり. stationごとにみればその限りではない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 分析対象の指定\n",
    "station_id = 70# station_idの指定．id=0のとき， 全station_idが対象\n",
    "landmark = ['', 'San Jose', 'San Francisco', 'Palo Alto', 'Mountain View', 'Redwood City'][0] # lanrmarkの指定． lanrmark = \"\"のとき，全landmarkが対象\n",
    "month = 0 # monthの指定. month=0のとき, 全ての月が対象．\n",
    "sub_title = \"\" #グラフのtitleに使用\n",
    "\n",
    "if station_id != 0: # station_idの指定がある場合\n",
    "    weekday= table.features[[\"Date\", \"Month\", \"Weekday\", \"Horidays\"]][table.features[\"Start ID\"] == station_id].copy()\n",
    "    sub_title = f\"station:{station_id}\"\n",
    "    \n",
    "    # installationからの日数\n",
    "    days = table.station[[\"station_id\",\"installation\"]].copy()\n",
    "    days[\"Days\"] = (pd.Timestamp(\"2016-08-31\") - days[\"installation\"]).dt.days\n",
    "    days = days.drop(\"installation\", axis=1)\n",
    "    days = days.set_index(\"station_id\")\n",
    "    days.reset_index(level=0, inplace=True)\n",
    "\n",
    "    # (設立日からの日数/7)で割り，各曜日1日あたりの利用回数を求める\n",
    "    weekday= weekday.groupby(\"Weekday\").size().to_frame(\"Count\")\n",
    "    weekday[\"Count\"] = weekday[\"Count\"] / (days.loc[days.station_id == station_id, \"Days\"].values[0] /7)\n",
    "    \n",
    "elif  landmark != '' and station_id == 0: # landmarkの指定がある場合(station_idの指定がある場合は無効)\n",
    "    weekday= table.features[[\"Date\", \"Month\", \"Weekday\", \"Horidays\"]][table.features[\"Start Landmark\"] == landmark].copy()\n",
    "    \n",
    "    # RedwoodCityのみ2014-02-20が稼働初日．\n",
    "    if landmark == \"Redwood City\":\n",
    "        weekday= weekday.groupby(\"Weekday\").size().to_frame(\"Count\") / 923\n",
    "    \n",
    "    # それ以外のlandmarkは2013-08-29に少なくとも1つのstationが稼働している．\n",
    "    else:\n",
    "        weekday= weekday.groupby(\"Weekday\").size().to_frame(\"Count\") / 3*365\n",
    "    sub_title = f\"landmark:{landmark}\"\n",
    "    \n",
    "else: # station_id, landmarkの指定がない場合は全てのデータを分析対象とする．\n",
    "    weekday= table.features[[\"Date\", \"Month\", \"Weekday\", \"Horidays\"]].copy()\n",
    "    weekday= weekday.groupby(\"Weekday\").size().to_frame(\"Count\") / (3*365)\n",
    "    sub_title = \"All data\"\n",
    "\n",
    "#  月の指定がある場合(毎月同じような傾向に)\n",
    "if month != 0:\n",
    "    weekday = weekday[weekday.Month == month].copy()\n",
    "    print(\"Month：\", month)\n",
    "\n",
    "# 可視化\n",
    "weekday.size().max(axis=0)).plot(kind=\"bar\", title = f\"Trip count per day by day of  week({sub_title})\", figsize=(8, 5), color=\"dodgerblue\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時間帯ごとの貸出or返却台数の分布を確認\n",
    " この傾向も使いたいけど, 時間帯も説明変数に入れるとHoridaysとの相関が下がったりして精度が落ちた．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 分析するデータの指定\n",
    "station_id =70 # station_idの指定. station_idのとき，全てのstationが対象\n",
    "landmark = ['', 'San Jose', 'San Francisco', 'Palo Alto', 'Mountain View', 'Redwood City'][0] # landmarkの指定．lanrmark = \"\"のとき全てのlandmark\n",
    "month = 0 # month = 0のとき，全てのデータ\n",
    "sub_title = \"\" #グラフのtitleに使用\n",
    "time_distribution = table.features.copy()\n",
    "\n",
    "if station_id != 0:\n",
    "    time_distribution = time_distribution[(time_distribution[\"Start ID\"] == station_id)\n",
    "                                         | (time_distribution[\"End ID\"] == station_id)][[\"Time\"]].copy()\n",
    "    days_sub = table.station[[\"station_id\",\"installation\"]].copy()\n",
    "    days_sub[\"Days\"] = (pd.Timestamp(\"2016-08-31\") - days_sub[\"installation\"]).dt.days\n",
    "    days = days_sub.loc[days_sub.station_id == station_id, \"Days\"].values[0] \n",
    "    sub_title = f\"station:{station_id}\"\n",
    "elif landmark != '':\n",
    "    time_distribution = time_distribution[(time_distribution[\"Start landmark\"] == landmark) | \n",
    "                                          (time_distribution[\"End landmark\"] == landmark)][[\"Time\"]].copy()\n",
    "    sub_title = f\"landmark:{landmark}\"\n",
    "    # 稼働日数\n",
    "    if landmark == \"Redwood City\":\n",
    "        days = 923\n",
    "    else:\n",
    "        days =  3*365      \n",
    "    sub_title = f\"landmark:{landmark}\"\n",
    "else:\n",
    "    time_distribution = time_distribution[[\"Time\"]].copy() #改善の余地あり．\n",
    "    days =  3*365  \n",
    "    sub_title = \"All data\"\n",
    "    \n",
    "# 月を指定する場合(毎月同じような傾向に)\n",
    "if month != 0:\n",
    "    time_distribution = table.features[table.features[\"Month\"] == month].copy()\n",
    "    sub_title += f\", month:{month}\"\n",
    "    \n",
    "ax = (time_distribution.groupby(\"Time\").size() / (360*3)).plot(\n",
    "    kind=\"bar\", title=f\"Distribution of trip count per hour ({sub_title})\", figsize=(8, 5), color=\"dodgerblue\")\n",
    "ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly.corr().Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 機械学習による貸出・返却台数の予測  \n",
    "  \n",
    "目的変数：1日あたりの貸出・返却台数(の範囲)  \n",
    "説明変数：平均気温, 降水量, 平日or休日← 時間帯を考慮するとscore大幅down　　\n",
    "\n",
    "回帰：重回帰分析 ← 台数  \n",
    "分類：k近傍法, 決定木, ランダムフォレスト, SVM, ロジスティック回帰 ← 台数の範囲や非稼働状態になるかどうかなど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# 重回帰分析\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# リッジ回帰\n",
    "from sklearn.linear_model import Ridge\n",
    "# k近傍法\n",
    "from sklearn.neighbors import  KNeighborsRegressor   \n",
    "# KernelRidge\n",
    "# from sklearn.kernel_ridge import KernelRidge    \n",
    "# DT\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# RF\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# SVM\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = [\n",
    "    LinearRegression(), Ridge(), KNeighborsRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), SVR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # 1日(or 時間帯)ごとの貸出数・返却数を表すデータフレームを作成する関数\n",
    "def create_df(station_id, rental, classification, period, season): #classification\n",
    "    \n",
    "    count_or_range = \"Range\" if classification else \"Count\"\n",
    "    \n",
    "\n",
    "    # 指定のstation_idのStart(End) Dateを抽出\n",
    "    from_x = table.trip[[\"Start Terminal\", \"Start Date\"]][table.trip[\"Start Terminal\"] == station_id].reset_index(drop = True)\n",
    "    to_x = table.trip[[\"End Terminal\", \"End Date\"]][table.trip[\"End Terminal\"] == station_id].reset_index(drop = True)\n",
    "\n",
    "        \n",
    "    #1日(or 時間帯)ごとの貸出数・返却数を表すountデータフレームを作成．後からweatherデータフレームと結合\n",
    "\n",
    "    # Start(End) Dateの日付と時間帯を抽出のみを抽出\n",
    "    from_x[\"Date\"] = pd.Series(map(lambda x:x.date(),  from_x[\"Start Date\"]))\n",
    "    from_x[\"Time\"] = list(map(lambda x:int(x.hour), from_x[\"Start Date\"]))        \n",
    "    to_x[\"Date\"] = pd.Series(map(lambda x:x.date(), to_x[\"End Date\"]))\n",
    "    to_x[\"Time\"] = list(map(lambda x:int(x.hour), to_x[\"End Date\"]))\n",
    "\n",
    "\n",
    "#     時間帯ごとに分類．　(-10:00 → 0， 10:00 - 15:00 → 1, 15:00-:2)\n",
    "    from_x.loc[from_x[\"Time\"] < 10, \"Time\"] = 0\n",
    "    from_x.loc[from_x[\"Time\"] >= 15, \"Time\"] = 2\n",
    "    from_x.loc[from_x[\"Time\"]>= 10, \"Time\"] = 1 # from_x = from_x.reset_index(level=[\"Time\"]) # Timeをインデックスからカラムに\n",
    "    from_x = from_x.groupby([\"Date\", \"Time\"]).size().unstack().fillna(0).stack().to_frame(\"Rental Count\")       \n",
    "    to_x.loc[to_x[\"Time\"] < 10, \"Time\"] = 0\n",
    "    to_x.loc[to_x[\"Time\"] >= 15, \"Time\"] = 2\n",
    "    to_x.loc[to_x[\"Time\"]>= 10, \"Time\"] = 1 #\n",
    "\n",
    "    to_x = to_x.groupby([\"Date\", \"Time\"]).size().unstack().fillna(0).stack().to_frame(\"Return Count\")\n",
    "\n",
    "    # 結合\n",
    "    count = from_x.join(to_x)\n",
    "    count = count.reset_index(level = [\"Time\"]).fillna(0) # ゼロフィル\n",
    "\n",
    "    # 休日を1, 平日を0とするHoridaysカラムを追加\n",
    "    count[\"Weekday\"] = pd.Series(map(lambda x:x.weekday(), count.index), index = count.index)\n",
    "    count[\"Horidays\"] = (count[\"Weekday\"] <= 4).astype(int)\n",
    "    count = count[[\"Weekday\", \"Time\", \"Rental Count\", \"Return Count\"]] # \"Horidays\",\n",
    "        \n",
    "        \n",
    "\n",
    "     # weatherから必要な情報を抽出し， weatherデータフレームを作る\n",
    "\n",
    "     # landmarkの取得\n",
    "    landmark = table.station.landmark[table.station.station_id == station_id].values[0]\n",
    "\n",
    "    # weatherテーブルから， stationとlandmarkが一致する行を抽出し， Dateをインデックスとして指定する．\n",
    "    weather = table.weather[table.weather.landmark == landmark].set_index(\"PDT\")    \n",
    "    weather.index.names = [\"Date\"]  \n",
    "\n",
    "    if season: # 季節を考慮\n",
    "        # 月のカラムを追加後，Monthをカテゴリに分けてSeasonカラムを追加\n",
    "        #  => 精度への影響は小さいが相関は強くなる ＊Mean Tempと意味合いが近いので削除\n",
    "        # ロサンゼルスの気候： https://allabout.co.jp/gm/gc/302803/\n",
    "        weather[\"Month\"] = pd.Series(map(lambda x:x.month, weather.index), index = weather.index)\n",
    "        weather.loc[weather.Month.isin([11,12,1]),\"Season\"] = 0 # 11～1月：冬(0) \n",
    "        weather.loc[weather.Month.isin([2,3]),\"Season\"] = 1 #2~3月： 春から初夏．(1) \n",
    "        weather.loc[weather.Month>=2,\"Season\"]= 2 # 4～10月：夏(2)\n",
    "\n",
    "    if classification:\n",
    "        # Countを5区切りで5つのカテゴリに分ける．\n",
    "        count.loc[count[\"Rental Count\"].isin(list(range(0,3))),\"Rental Range\"] = 0 # 0~4\n",
    "        count.loc[count[\"Rental Count\"].isin(list(range(3,6))),\"Rental Range\"] = 1\n",
    "        count.loc[count[\"Rental Count\"].isin(list(range(6,9))),\"Rental Range\"] = 2\n",
    "        count.loc[count[\"Rental Count\"].isin(list(range(9,12))),\"Rental Range\"] = 3\n",
    "        count.loc[count[\"Rental Count\"] >=12, \"Rental Range\"] = 4\n",
    "        count = count.drop(\"Rental Count\", axis=1)\n",
    "\n",
    "        count.loc[count[\"Return Count\"].isin(list(range(0,3))),\"Return Range\"] = 0 # 0~4\n",
    "        count.loc[count[\"Return Count\"].isin(list(range(3,6))),\"Return Range\"] = 1\n",
    "        count.loc[count[\"Return Count\"].isin(list(range(6,9))),\"Return Range\"] = 2\n",
    "        count.loc[count[\"Return Count\"].isin(list(range(9,12))),\"Return Range\"] = 3\n",
    "        count.loc[count[\"Return Count\"] >=12, \"Return Range\"] = 4\n",
    "        count = count.drop(\"Return Count\", axis=1)\n",
    "        \n",
    "    if rental:\n",
    "        count = count.drop(f\"Return {count_or_range}\", axis=1)\n",
    "    else:\n",
    "        count = count.drop(f\"Rental {count_or_range}\", axis=1)\n",
    "        \n",
    "\n",
    "    # countとweatherを結合\n",
    "    weather_count = weather.join(count)\n",
    "\n",
    "    # 欠損値の削除\n",
    "    weather_count = weather_count.dropna()\n",
    "    \n",
    "    return weather_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "station_id =  70 # station_idの指定\n",
    "rental = True # :rental, False：return\n",
    "classification = False # True：分類(range), False：回帰(count)\n",
    "period = True # True：時間帯を考慮， False：時間帯を考慮しない\n",
    "season = False # True：季節を考慮，　False：季節を考慮しない\n",
    "\n",
    "df = create_df(station_id, rental, classification, period, season)\n",
    "\n",
    "# 相関行列を取得し，相関係数の絶対値が降順になるようにソート\n",
    "corr = df.corr().copy()\n",
    "corr[\"abs\"] = corr[\"Rental Count\"].abs()\n",
    "corr = corr.sort_values(\"abs\", ascending=False).drop(\"Rental Count\", axis=0)\n",
    "\n",
    "# 特徴量の自動生成\n",
    "feature_list = []\n",
    "# 最も相関が高い特徴量を追加\n",
    "feature_list.append(corr.index[0])\n",
    "for i in range(1, len(corr)):\n",
    "    if ((corr.loc[corr.index[i], \"abs\"]) >= 0.15) and (max(corr.loc[corr.index[i], feature_list]) < 0.7):\n",
    "        feature_list.append(corr.index[i])\n",
    "    if len(feature_list) == 4:\n",
    "        break\n",
    "print(int(station_id), \":\", feature_list)\n",
    "print()\n",
    "\n",
    "X = df[feature_list] #, \"Max Gust SpeedMPH\", \"Mean Wind SpeedMPH\"\n",
    "y = df[[\"Rental Count\"]].values.ravel()\n",
    "       \n",
    "# 訓練データとテストデータに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 標準化(必要?)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "       \n",
    "#  ノーフリーランチ\n",
    "best_score = 0\n",
    "best_model = \"\"\n",
    "for model in models:\n",
    "    clf = model.fit(X_train_std,y_train)\n",
    "    print(f\"{clf.__class__.__name__}\")\n",
    "    print(f\"train:{clf.score(X_train_std, y_train)}\")\n",
    "    print(f\"test:{clf.score(X_test_std, y_test)}\")\n",
    "    print()\n",
    "    if clf.score(X_test_std, y_test) > best_score:\n",
    "        best_score  = clf.score(X_test_std, y_test)\n",
    "        best_model = clf.__class__.__name__\n",
    "    \n",
    "# グリッドサーチ\n",
    "score_list = []\n",
    "best_score = 0\n",
    "best_d = 0 \n",
    "for d in range(1, 10):\n",
    "    model = [DecisionTreeRegressor(max_depth=d), RandomForestRegressor(n_estimators=5, max_depth=n),  SVR(C=n)][0]\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score_list.append(clf.score(X_test, y_test))\n",
    "    if clf.score(X_test, y_test) > best_score:\n",
    "        best_score = clf.score(X_test, y_test)\n",
    "        best_d = d\n",
    "print(f\"d:{best_d} \\n score:{best_score}\")\n",
    "plt.plot(range(1, 10), score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 木を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習した結果をGraphvizが認識できる形式にして出力する\n",
    "from sklearn import tree\n",
    "clf =  DecisionTreeRegressor(max_depth=4).fit(X_train_std, y_train)\n",
    "with open('graph.dot', 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dot -Tpdf graph.dot -o graph.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### そもそも調べる必要があるstation_idを取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stationの稼働状態を表すDFを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# installationからの日数\n",
    "days = table.station[[\"station_id\",\"installation\"]].copy()\n",
    "days[\"Days\"] = (pd.Timestamp(\"2016-08-31\") - days[\"installation\"]).dt.days\n",
    "days = days.drop(\"installation\", axis=1)\n",
    "days = days.set_index(\"station_id\")\n",
    "days.reset_index(level=0, inplace=True)\n",
    "\n",
    "# bikes_available, docks_available=0の合計時間(min)\n",
    "no_bikes = (table.status[table.status.bikes_available == 0].groupby(\"station_id\").size()).to_frame(\"No Bikes\")\n",
    "no_docks = (table.status[table.status.docks_available == 0].groupby(\"station_id\").size()).to_frame(\"No Docks\")\n",
    "non_working = no_bikes.join(no_docks).fillna(0)\n",
    "non_working[\"Total\"] = non_working[\"No Bikes\"] + non_working[\"No Docks\"]\n",
    "non_working[\"station_id\"] = non_working.index\n",
    "non_working = non_working.reset_index(level=[\"station_id\"], drop=True)\n",
    "non_working= non_working[[\"station_id\", \"No Bikes\", \"No Docks\", \"Total\"]]\n",
    "\n",
    "# daysとnonworkingを結合\n",
    "non_working = pd.merge(non_working, days, on=\"station_id\")\n",
    "non_working[\"No Bikes\"] = non_working[\"No Bikes\"] / non_working[\"Days\"] \n",
    "non_working[\"No Docks\"] = non_working[\"No Docks\"] / non_working[\"Days\"] \n",
    "non_working[\"Total\"] = non_working[\"Total\"] / non_working[\"Days\"] \n",
    "non_working = non_working.rename(columns = {\n",
    "    \"No Bikes\":\"No_Bikes(min/day)\", \"No Docks\":\"No_Docks(min/day)\", \"Total\":\"No_Both(min/day)\"\n",
    "})\n",
    "non_working = non_working.drop([\"Days\"], axis=1)\n",
    "\n",
    "# 非稼働状態の時間が長い順にソート\n",
    "non_working = non_working.sort_values(by=[\"No_Both(min/day)\"], ascending = False)\n",
    "\n",
    "# landmarkとdo等の情報を追加\n",
    "non_working = pd.merge(table.station[[\"station_id\",\"dockcount\",\"landmark\", \"lat\", \"long\"]],non_working,on=[\"station_id\"])\n",
    "\n",
    "# 1日あたりの利用回数のカラムを追加．\n",
    "station_working = pd.merge(non_working, trip_count, on=\"station_id\")\n",
    "\n",
    "# San Franciscoのみを抽出\n",
    "# san_francisco =  station_working[station_working.landmark == \"San Francisco\"].sort_values(by=[\"No_Both(min/day)\"], ascending = False)\n",
    "# san_francisco.head()\n",
    "\n",
    "station_working.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_working.sort_values(\"No_Bikes(min/day)\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "bike_or_dock = [\"bike\", \"dock\"][0]\n",
    "\n",
    "if bike_or_dock==\"bike\":\n",
    "    X = station_working[\"No_Bikes(min/day)\"].reshape(-1, 1)\n",
    "elif  bike_or_dock==\"dock\":\n",
    "    X = station_working[\"No_Docks(min/day)\"].reshape(-1, 1)\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "sc1.fit(X)\n",
    "X = sc1.transform(X)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# エルボー法\n",
    "dist_list1 =[]\n",
    "for i in range(1,20):\n",
    "    kmpp1 = KMeans(n_clusters=i,init='random',n_init=5,max_iter=100,random_state=0)\n",
    "    kmpp1.fit(X)\n",
    "    dist_list1.append(kmpp1.inertia_)\n",
    "plt.plot(range(1,20),dist_list1,marker='x')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Disttortion\")\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "n = 3 # クラスター数\n",
    "# random_state固定\n",
    "kmeans = KMeans(init='random',n_clusters=n,random_state=0)\n",
    "kmeans.fit(pd.DataFrame(X)) \n",
    "station_working[\"cl_nm\"] = kmeans.labels_\n",
    "\n",
    "import gmaps\n",
    "gmaps.configure(api_key=\"AIzaSyARmLcIEdT5FC9PEBvNv2nFCVgTMw7NTT0\")\n",
    "fig = gmaps.figure(center=(37.491405, -122.233051), zoom_level=9)\n",
    "\n",
    "color_list =color_list = [\"rgba(255,69,0,1)\", \"rgba(255,255,0,1)\",   \"rgba(30,144,255, 1)\"] #\"rgba(50,205,50, 1)\",\n",
    "\n",
    "if bike_or_dock==\"bike\":\n",
    "    cl_nm_list=[0, 1,  2]\n",
    "else:\n",
    "    cl_nm_list=[1, 0, 2]\n",
    "\n",
    "for i in range(len(cl_nm_list)):\n",
    "    cl_nm=cl_nm_list[i]\n",
    "    color = color_list[i]\n",
    "    clusters = np.array(station_working[station_working.cl_nm == cl_nm][[\"lat\", \"long\"]])\n",
    "    cl_nm_layer= gmaps.symbol_layer(clusters, fill_color=color, stroke_color=color, scale=2)\n",
    "    fig.add_layer(cl_nm_layer)\n",
    "fig\n",
    "\n",
    "# station_working.groupby(\"cl_nm\")[\"No_Bikes(min/day)\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### available_docks=0, 1の時間をプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 稼働1日あたりの利用回数をプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各stationの1日あたりの貸出台数, 返却台数を格納したDataFrameの作成\n",
    "trip_count = table.station[[\"station_id\",\"installation\"]].copy()\n",
    "trip_count[\"Days\"] = (pd.Timestamp(\"2016-08-31\") - trip_count[\"installation\"]).dt.days\n",
    "trip_count = trip_count.drop(\"installation\", axis=1)\n",
    "trip_count = trip_count.set_index(\"station_id\")\n",
    "trip_count[\"Rental Count\"] = table.trip.groupby(\"Start Terminal\").size()\n",
    "trip_count[\"Rental per Day\"] = trip_count[\"Rental Count\"] / trip_count[\"Days\"]\n",
    "trip_count[\"Return Count\"] = table.trip.groupby(\"End Terminal\").size()\n",
    "trip_count[\"Return per Day\"] = trip_count[\"Return Count\"] / trip_count[\"Days\"]\n",
    "trip_count[\"Total Count\"] =trip_count[\"Rental Count\"] + trip_count[\"Return Count\"]\n",
    "trip_count[\"Total per Day\"] = trip_count[\"Total Count\"] / trip_count[\"Days\"]\n",
    "trip_count = trip_count.sort_values(\"Total per Day\", ascending=False)\n",
    "trip_count.reset_index(level=0, inplace=True)\n",
    "\n",
    "total_count_data = trip_count[[\"Total per Day\"]].sort_values(by=[\"Total per Day\"], ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc0 = StandardScaler()\n",
    "sc0.fit(total_count_data)\n",
    "total_count_data_std = sc0.transform(total_count_data)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X0 = total_count_data_std\n",
    "\n",
    "# エルボー法\n",
    "dist_list0 =[]\n",
    "for i in range(1,20):\n",
    "    kmpp0 = KMeans(n_clusters=i,init='random',n_init=5,max_iter=100,random_state=0)\n",
    "    kmpp0.fit(X0)\n",
    "    dist_list0.append(kmpp0.inertia_)\n",
    "plt.plot(range(1,20),dist_list0,marker='+', color=\"dodgerblue\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Disttortion\")\n",
    "\n",
    "# random_state固定\n",
    "kmeans0 = KMeans(init='random',n_clusters=4,random_state=94) #n_clusters=4,random_state=29\n",
    "kmeans0.fit(X0)\n",
    "labels0 = kmeans0.labels_\n",
    "label_data0 = pd.DataFrame(labels0,columns=[\"cl_nm\"])\n",
    "clusters_data0 = pd.concat([total_count_data,label_data0],axis=1)\n",
    "\n",
    "for_merge_data0=pd.merge(trip_count[[\"station_id\",\"Total per Day\"]],clusters_data0,on=[\"Total per Day\"]).sort_values(by=[\"station_id\"],ascending=True)\n",
    "merge_data0 = pd.merge(table.station,for_merge_data0,on=[\"station_id\"])\n",
    "\n",
    "import gmaps\n",
    "gmaps.configure(api_key=\"AIzaSyARmLcIEdT5FC9PEBvNv2nFCVgTMw7NTT0\")\n",
    "fig = gmaps.figure(center=(37.491405, -122.233051), zoom_level=9)\n",
    "\n",
    "cl_nm_list=[3, 1, 0, 2] \n",
    "color_list = [\"rgba(255,69,0,1)\", \"rgba(255,255,0,1)\", \"rgba(50,205,50, 1)\",  \"rgba(30,144,255, 1)\"]\n",
    "\n",
    "for i in range(len(cl_nm_list)):\n",
    "    cl_nm=cl_nm_list[i]\n",
    "    color = color_list[i]\n",
    "    clusters = np.array(merge_data0[merge_data0.cl_nm == cl_nm][[\"lat\", \"long\"]])\n",
    "    cl_nm_layer= gmaps.symbol_layer(clusters, fill_color=color, stroke_color=color, scale=2)\n",
    "    fig.add_layer(cl_nm_layer)\n",
    "\n",
    "# merge_data0.groupby(\"cl_nm\").describe()\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 気づいたこと\n",
    "①バイクのない時間が長い(merge_data1[merge_data1.cl_nm==2] )のは全てSanFrancisco\n",
    "\n",
    "②赤いところ Total per Dayは少ない　＝　使用台数が少ないのにバイクが使えない時間が長い　＝バイクが足りてない\n",
    "    \n",
    "    (具体的には　merge_data1[merge_data1.cl_nm==2].station_id で出てくる。\n",
    "    station_idだと41,  45,  48,  60,  62,  63,  70,  73, 76, 82）\n",
    "\n",
    "\n",
    "\n",
    "原因：\n",
    "\n",
    "①観光地で使う人が多いから？（遠出？近場？） \n",
    "\n",
    "→観光地かどうかは見れない\n",
    "\n",
    "②そもそもDockが少ないのか？　\n",
    "\n",
    "→少なそう。すぐに調べられる。平均値は18.3。merge_data1[merge_data1.cl_nm==2].dockcountは全部15~19で改良の余地あり\n",
    "\n",
    "③Anuualがめっちゃ多いのか？\n",
    "\n",
    "→下のデータからstation_id =48と60のみ観光客が多い（73,76は普通）が、他はAnnualがかなり多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### San Franciscoの考慮すべき全stationのscoreを取得\n",
    "randomforestは過学習  \n",
    "SVRも精度微妙  \n",
    "回帰木は下の4つが著しく精度わるいから要確認．\n",
    "66.0, 71.0, 46.0, 58.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# データ数が少ない90, 91は削除\n",
    "sanfrancisco_id = list(table.station[table.station.landmark == \"San Francisco\"].station_id)\n",
    "sanfrancisco_id.remove(90)\n",
    "sanfrancisco_id.remove(91)\n",
    "\n",
    "\n",
    "# 全station_idのスコアを取得 # 88\n",
    "score_dic = {}\n",
    "for station_id in sanfrancisco_id:\n",
    "    \n",
    "    # dfの作成\n",
    "    rental = True # :rental, False：return\n",
    "    classification = False # True：分類(range), False：回帰(count)\n",
    "    period = True # True：時間帯を考慮， False：時間帯を考慮しない\n",
    "    season = False # True：季節を考慮，　False：季節を考慮しない\n",
    "    df = create_df(station_id, rental, classification, period, season)\n",
    "    \n",
    "    if station_id == 88: #88はrantal_rangeが全て0ゆえエラー\n",
    "        df.iloc[0, 3] = 1 # 無理やり一つを1にする．\n",
    "        \n",
    "    # 相関行列を取得し，相関係数の絶対値が降順になるようにソート\n",
    "    corr = df.corr().copy()\n",
    "    corr[\"abs\"] = corr[\"Rental Count\"].abs()\n",
    "    corr = corr.sort_values(\"abs\", ascending=False).drop(\"Rental Count\", axis=0)\n",
    "        \n",
    "    # 特徴量の自動生成\n",
    "    feature_list = []\n",
    "    # 最も相関が高い特徴量を追加\n",
    "    feature_list.append(corr.index[0])\n",
    "    for i in range(1, len(corr)):\n",
    "        if ((corr.loc[corr.index[i], \"abs\"]) >= 0.1) and (max(corr.loc[corr.index[i], feature_list]) < 0.7):\n",
    "            feature_list.append(corr.index[i])\n",
    "        if len(feature_list) == 5:\n",
    "            break\n",
    "    print(\"station\", int(station_id))\n",
    "    print(\"features: \", feature_list)\n",
    "\n",
    "    X = df[feature_list] #, \"Max Gust SpeedMPH\", \"Mean Wind SpeedMPH\"\n",
    "    y = df[[\"Rental Count\"]].values.ravel()\n",
    "\n",
    "    # 訓練データとテストデータに分割\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # 標準化\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train=sc.transform(X_train)\n",
    "    X_test= sc.transform(X_test)\n",
    "    \n",
    "    # グリッドサーチ\n",
    "    best_d = 1\n",
    "    best_score = 0\n",
    "    for d in range(1, 20):\n",
    "        clf = DecisionTreeRegressor(max_depth=d).fit(X_train, y_train)\n",
    "        if clf.score(X_test, y_test) >  best_score:\n",
    "            best_score = clf.score(X_test, y_test) \n",
    "            best_d = d\n",
    "    clf = model.fit(X_train,y_train)\n",
    "    score_dic[station_id] = [clf.score(X_test, y_test)]\n",
    "\n",
    "    # 回帰木\n",
    "    model = DecisionTreeRegressor(max_depth=best_d)\n",
    "    clf = model.fit(X_train,y_train)\n",
    "    print(\"train\", clf.score(X_train, y_train))\n",
    "    print(\"test:\", clf.score(X_test, y_test)) #\"model:\", best_model,\n",
    "    print(\"max_depth\", best_d)\n",
    "    print()\n",
    "    score_dic[station_id] = [clf.score(X_test, y_test)]\n",
    "    \n",
    "scores = np.array(list(map(lambda x:x, score_dic.values())))\n",
    "scores = np.array(list(score_dic.values()))\n",
    "sorted_score =  sorted(score_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print()\n",
    "print(\"DecisionTreeRegressor\")\n",
    "print(\"avarage:\",  np.array(list(score_dic.values())).mean())\n",
    "print(\"over 0.8:\", (np.array(list(score_dic.values())) > 0.8).sum())\n",
    "print(\"over 0.7:\", (np.array(list(score_dic.values())) > 0.7).sum())\n",
    "print(\"over 0.6:\", (np.array(list(score_dic.values())) > 0.6).sum())\n",
    "sorted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の検証  \n",
    "精度が高いstationと低いstationの特徴を調べるためにとりあえずstationごとの(1日あたりの)trip数とscoreの相関を確認する  \n",
    "スコアが02以下のは極端にデータが少ないやつだから消しても良さそう．  \n",
    "データが集まっているのに精度が低いstationをなんとかしたい． Horidaysを説明変数にとっているのが問題な気がする．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_score = trip_count[trip_count.station_id.isin(table.station[table.station.landmark == \"San Francisco\"].station_id)].copy().set_index(\"station_id\")\n",
    "\n",
    "count_score = count_score.join(pd.DataFrame(pd.DataFrame(score_dic).stack().reset_index(level=0, drop=True), columns=[\"Score\"])).reset_index()\n",
    "\n",
    "\n",
    "a = count_score.plot.scatter(x=\"Total Count\",y=\"Score\", figsize=(7, 7), color=\"dodgerblue\", \n",
    "                             title='The relationship between \"Total Count\" and \"Score\"')\n",
    " \n",
    "count_score = count_score[[\"station_id\", \"Total Count\", \"Score\"]] # .set_index([\"station_id\"])\n",
    "\n",
    "# 各要素にラベルを表示\n",
    "for k, v in count_score.iterrows():\n",
    "    a.annotate(v[0], xy=(v[1],v[2]), size=7.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＊参考 スコアとの比較\n",
    "score: station_id  \n",
    "0.7~: 88, 55, 2, 63, 45, 62, 56, 75, 51, 41 (88は全てrange=0でscore=1)  \n",
    "0.6~: 42, 66, 49, 57, 47, 59, 28, 64 ← ここも全部休日と平日の区別が明確だからチューニングで0.7超えそう  \n",
    "0.5~: 69, 65, 48, 77 ← ここも上と同様(48以外)  \n",
    "0.4~: 74, 71, 68, 72  ← ここも(71以外)  \n",
    "0.3~: 27, 82, 4, 67, 61, 73, 70, 39, 54 ← 27, 82, 67, 61, 73あたりには傾向あり  \n",
    "0.2~: 32, 60, 58, 76, 46 ← 0.3未満は土日と平日の区別ほぼなし  \n",
    "~0.1: 50, 29, 30, 10, 6, 5, 84, 34, 35, 31, 80, 11, 9, 7, 37, 16, 33, 13, 36, 8, 90, 3, 91, 12, 14, 89, 83, 38 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
